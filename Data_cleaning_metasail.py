import pandas as pd
import re
from names_dataset import NameDataset
import numpy as np
from datetime import timedelta, datetime
from thefuzz import fuzz


class DataCleaningAndPreprocessing:
    """
    Une classe pour nettoyer, pr√©traiter, et fusionner des donn√©es statistiques
    provenant de Metasail avec des donn√©es m√©t√©o.
    """

    def __init__(self, file_path_metasail, file_path_weather):
        """
        Initialise la classe et charge les jeux de donn√©es.
        :param file_path_metasail: Chemin vers le fichier Excel de Metasail.
        :param file_path_weather: Chemin vers le fichier Excel de m√©t√©o.
        """
        try:
            self.df_metasail = pd.read_excel(file_path_metasail)
            self.df_weather = pd.read_excel(file_path_weather)
            print("‚úÖ Fichiers Excel charg√©s avec succ√®s.")

            self.nd = NameDataset()  # Initialise la base de donn√©es de pr√©noms
        except FileNotFoundError:
            print(f"‚ùå Erreur : Un des fichiers n'a pas √©t√© trouv√©.")
            self.df_metasail = None
            self.df_weather = None
        except Exception as e:
            print(f"‚ùå Une erreur s'est produite lors de la lecture des fichiers : {e}")
            self.df_metasail = None
            self.df_weather = None

        self.ready_to_process = self.df_metasail is not None and self.df_weather is not None

    def run_cleaning_and_preprocessing(self):
        """
        Ex√©cute l'ensemble des √©tapes de nettoyage et de pr√©traitement des donn√©es.
        """
        if not self.ready_to_process:
            print("‚ùå Traitement annul√© : Les DataFrames n'ont pas √©t√© charg√©s correctement.")
            return

        print("\n" + "=" * 50)
        print("üöÄ D√âBUT DU NETTOYAGE ET DU PR√âTRAITEMENT")
        print("=" * 50)

        # 1. Nettoyage des donn√©es Metasail
        self._clean_metasail_data()

        # 2. Pr√©paration et fusion des donn√©es m√©t√©o
        self._prepare_data_for_merge()
        self._find_closest_weather_data()

        # 3. Calcul des m√©triques
        self._recalculate_and_clean_metrics()

        print("\n" + "=" * 50)
        print("‚úÖ FIN DU NETTOYAGE ET DU PR√âTRAITEMENT")
        print("=" * 50)

    def _clean_metasail_data(self):
        """
        Nettoie et pr√©traite le DataFrame Metasail.
        """
        if self.df_metasail is None:
            return

        print("\n" + "---" * 15)
        print("üóëÔ∏è √âTAPE 1 : NETTOYAGE DES DONN√âES METASAIL")
        print("---" * 15)

        colonnes_a_supprimer = [
            'Position de d√©part', 'Classement sortie de segment', 'Vitesse maximale (noeuds)',
            'VMG maximale', 'VMC maximale', 'VMG moyenne'
        ]
        self.df_metasail.drop(columns=colonnes_a_supprimer, inplace=True, errors='ignore')
        print(f"üóëÔ∏è Colonnes supprim√©es : {colonnes_a_supprimer}")

        if 'Nom complet' in self.df_metasail.columns:
            self.df_metasail['Nom complet'] = self.df_metasail['Nom complet'].astype(str).str.strip().str.replace("'",
                                                                                                                  " ")
            self._unify_names()
            print("üßπ Nettoyage et unification des noms complets effectu√©s.")

        self._process_course_column()
        self._filter_race_status()
        self._split_date()
        self._complete_missing_gender()
        self._complete_missing_age()

    def _unify_names(self, threshold=85):
        """
        Unifie les noms complets qui sont tr√®s similaires en utilisant TheFuzz.
        :param threshold: Seuil de similarit√© (de 0 √† 100).
        """
        unique_names = self.df_metasail['Nom complet'].dropna().unique()
        name_mapping = {}
        for name in unique_names:
            found_group = False
            if name in name_mapping.keys():
                continue
            for group_name in name_mapping.keys():
                if fuzz.ratio(name.lower(), group_name.lower()) > threshold:
                    name_mapping[name] = group_name
                    found_group = True
                    break
            if not found_group:
                name_mapping[name] = name
        self.df_metasail['Nom complet'] = self.df_metasail['Nom complet'].map(name_mapping)

    def _process_course_column(self):
        """Extrait la cat√©gorie d'√¢ge et le sexe de la colonne 'Course'."""
        if 'Course' not in self.df_metasail.columns:
            print("‚ö†Ô∏è Colonne 'Course' introuvable. Traitement de la course ignor√©.")
            return
        print("üîÑ Traitement de la colonne 'Course'...")
        colonne_course = self.df_metasail['Course'].astype(str)
        self.df_metasail['Sexe'] = colonne_course.str.extract(r'(Men|Women)', flags=re.IGNORECASE,
                                                              expand=False).str.capitalize()
        pattern_u17 = r'U\s*17|Under\s*17|JUNIOR'
        pattern_u19 = r'U\s*19|Under\s*19|YOUTH'
        self.df_metasail["Cat√©gorie d'√¢ge"] = pd.Series(dtype='object')
        self.df_metasail.loc[
            colonne_course.str.contains(pattern_u17, flags=re.IGNORECASE, na=False), "Cat√©gorie d'√¢ge"] = 'U17'
        self.df_metasail.loc[
            colonne_course.str.contains(pattern_u19, flags=re.IGNORECASE, na=False), "Cat√©gorie d'√¢ge"] = 'U19'
        pattern_a_supprimer = f"({pattern_u17}|{pattern_u19}|Men|Women|IQfoil)"
        course_nettoyee = colonne_course.str.replace(pattern_a_supprimer, '', flags=re.IGNORECASE, regex=True)
        self.df_metasail['Course'] = course_nettoyee.str.replace(r'\s+', ' ', regex=True).str.strip()
        print("‚úÖ Colonnes 'Sexe' et 'Cat√©gorie d'√¢ge' cr√©√©es et colonne 'Course' nettoy√©e.")

    def _filter_race_status(self):
        """Supprime les lignes 'abandonned' ou 'recall'."""
        if 'Course' not in self.df_metasail.columns:
            print("‚ö†Ô∏è Colonne 'Course' introuvable. Filtrage de la course ignor√©.")
            return
        lignes_initiales = len(self.df_metasail)
        self.df_metasail = self.df_metasail[
            ~self.df_metasail['Course'].str.contains('abandon|recall', case=False, na=False)]
        lignes_supprimees = lignes_initiales - len(self.df_metasail)
        print(f"‚úÖ {lignes_supprimees} ligne(s) 'abandonned' ou 'recall' supprim√©e(s).")

    def _split_date(self, nom_colonne_date='Date de la course'):
        """Divise une colonne de date en Ann√©e, Mois, Jour."""
        if nom_colonne_date not in self.df_metasail.columns:
            print(f"‚ö†Ô∏è Colonne '{nom_colonne_date}' introuvable. Split de la date ignor√©.")
            return
        self.df_metasail[nom_colonne_date] = pd.to_datetime(self.df_metasail[nom_colonne_date])
        self.df_metasail['Ann√©e'] = self.df_metasail[nom_colonne_date].dt.year
        self.df_metasail['Mois'] = self.df_metasail[nom_colonne_date].dt.month
        self.df_metasail['Jour'] = self.df_metasail[nom_colonne_date].dt.day
        self.df_metasail.drop(columns=[nom_colonne_date], inplace=True)
        print(f"‚úÖ Colonnes Ann√©e, Mois, Jour cr√©√©es et colonne '{nom_colonne_date}' supprim√©e.")

    def _complete_missing_gender(self):
        """
        Remplit les sexes manquants en utilisant 'Nom complet' en trouvant le pr√©nom
        le plus probable.
        """
        if 'Nom complet' not in self.df_metasail.columns or 'Sexe' not in self.df_metasail.columns:
            print("‚ö†Ô∏è Colonnes 'Nom complet' ou 'Sexe' introuvables. Impossible de compl√©ter le sexe.")
            return
        print("üîÑ Compl√©tion des sexes manquants...")

        def predire_sexe_par_prenom(nom_complet):
            if not isinstance(nom_complet, str) or not nom_complet:
                return np.nan
            mots = nom_complet.split()
            best_first_name_data = None
            max_first_name_rank = float('inf')
            for mot in mots:
                resultat = self.nd.search(mot)
                if resultat and 'first_name' in resultat and resultat['first_name'] and 'rank' in resultat[
                    'first_name']:
                    ranks = {k: v for k, v in resultat['first_name']['rank'].items() if v is not None}
                    if ranks:
                        best_rank_country = min(ranks, key=ranks.get)
                        current_rank = ranks[best_rank_country]
                        if current_rank < max_first_name_rank:
                            max_first_name_rank = current_rank
                            best_first_name_data = resultat['first_name']
            if best_first_name_data and 'gender' in best_first_name_data:
                prob_male = best_first_name_data['gender'].get('Male', 0)
                prob_female = best_first_name_data['gender'].get('Female', 0)
                if prob_female > prob_male:
                    return 'Women'
                elif prob_male > prob_female:
                    return 'Men'
            return np.nan

        masque_sexe_vide = self.df_metasail['Sexe'].isnull()
        self.df_metasail.loc[masque_sexe_vide, 'Sexe'] = self.df_metasail.loc[masque_sexe_vide, 'Nom complet'].apply(
            predire_sexe_par_prenom)
        print("‚úÖ Tentative de compl√©tion des sexes manquants termin√©e.")

    def _complete_missing_age(self):
        """
        Remplit les √¢ges manquants en se basant sur le m√™me "Num√©ro de s√©rie" et "Nom complet".
        """
        if "Cat√©gorie d'√¢ge" not in self.df_metasail.columns or 'Num√©ro de s√©rie' not in self.df_metasail.columns or 'Nom complet' not in self.df_metasail.columns:
            print("‚ö†Ô∏è Colonnes d'√¢ge ou d'identification manquantes. Compl√©tion de l'√¢ge ignor√©e.")
            return
        print("üîÑ Compl√©tion des √¢ges manquants...")
        valeurs_valides = \
        self.df_metasail.dropna(subset=["Cat√©gorie d'√¢ge"]).set_index(['Num√©ro de s√©rie', 'Nom complet'])[
            "Cat√©gorie d'√¢ge"].to_dict()

        def appliquer_age(row):
            if pd.isnull(row["Cat√©gorie d'√¢ge"]):
                cle = (row['Num√©ro de s√©rie'], row['Nom complet'])
                return valeurs_valides.get(cle, "Senior")
            return row["Cat√©gorie d'√¢ge"]

        self.df_metasail["Cat√©gorie d'√¢ge"] = self.df_metasail.apply(appliquer_age, axis=1)
        print("‚úÖ Compl√©tion des √¢ges manquants termin√©e.")

    def _prepare_data_for_merge(self):
        """
        Pr√©pare les DataFrames Metasail et m√©t√©o pour la fusion.
        """
        print("\n" + "---" * 15)
        print("üõ†Ô∏è √âTAPE 2 : PR√âPARATION ET FUSION DES DONN√âES")
        print("---" * 15)

        # Pr√©paration des dates de Metasail
        self.df_metasail["Date"] = pd.to_datetime(
            self.df_metasail[["Ann√©e", "Mois", "Jour"]].astype(str).agg("-".join, axis=1), errors="coerce").dt.date
        base_dt_metasail = pd.to_datetime(
            self.df_metasail['Ann√©e'].astype(str) + '-' + self.df_metasail['Mois'].astype(str) + '-' + self.df_metasail[
                'Jour'].astype(str), errors='coerce')
        start_timedelta = pd.to_timedelta(self.df_metasail["D√©but du segment (timestamp)"].astype(str))
        end_timedelta = pd.to_timedelta(self.df_metasail["Fin du segment (timestamp)"].astype(str))
        self.df_metasail["D√©but du segment_dt"] = base_dt_metasail + start_timedelta
        self.df_metasail["Fin du segment_dt"] = base_dt_metasail + end_timedelta
        self.df_metasail.loc[self.df_metasail["Fin du segment_dt"] < self.df_metasail[
            "D√©but du segment_dt"], "Fin du segment_dt"] += timedelta(days=1)
        self.df_metasail["Temps du segment_dt"] = (self.df_metasail["D√©but du segment_dt"] + (
                    self.df_metasail["Fin du segment_dt"] - self.df_metasail["D√©but du segment_dt"]) / 2).dt.time

        # Pr√©paration des dates de m√©t√©o
        self.df_weather["Date"] = pd.to_datetime(
            self.df_weather[["Year", "Month", "Day"]].astype(str).agg("-".join, axis=1), errors="coerce").dt.date
        self.df_weather['Time_dt'] = pd.to_datetime(self.df_weather['Time'].astype(str), format='%H:%M:%S').dt.time

        print("‚úÖ Donn√©es de date et heure pr√©par√©es.")

    def _find_closest_weather_data(self):
        """
        Recherche et fusionne les donn√©es m√©t√©o les plus proches pour chaque ligne de Metasail.
        """
        print("üîç Fusion des donn√©es m√©t√©o...")

        # Pr√©parez la colonne de lieu dans Metasail pour la fusion
        if "Lieu de l'√©v√©nement" not in self.df_metasail.columns:
            print("‚ùå Colonne 'Lieu de l'√©v√©nement' manquante. Impossible de fusionner les donn√©es m√©t√©o.")
            return

        coords = self.df_metasail["Lieu de l'√©v√©nement"].astype(str).str.split(", ", expand=True)
        if coords.shape[1] < 2:
            print("‚ùå Format de coordonn√©es invalide. Impossible de fusionner les donn√©es m√©t√©o.")
            return

        self.df_metasail['Lat_rounded'] = pd.to_numeric(coords[0], errors='coerce').round(4)
        self.df_metasail['Lon_rounded'] = pd.to_numeric(coords[1], errors='coerce').round(4)
        self.df_metasail['Lieu_key'] = 'Location (' + self.df_metasail['Lat_rounded'].astype(str) + ', ' + \
                                       self.df_metasail['Lon_rounded'].astype(str) + ')'

        # Pr√©parez la colonne de ville m√©t√©o pour la fusion
        self.df_weather['City_key'] = self.df_weather['City'].astype(str)

        # Effectuez une fusion pour chaque couple Lieu/Date
        final_df_list = []
        ignored_locations = set()

        # Itere sur les combinaisons uniques de lieu et de date du dataframe metasail
        unique_locations_dates = self.df_metasail[['Lieu_key', 'Date']].drop_duplicates()

        for _, row in unique_locations_dates.iterrows():
            lieu_key = row['Lieu_key']
            date = row['Date']

            metasail_subset = self.df_metasail[
                (self.df_metasail['Lieu_key'] == lieu_key) & (self.df_metasail['Date'] == date)].copy()
            weather_subset = self.df_weather[
                (self.df_weather['City_key'] == lieu_key) & (self.df_weather['Date'] == date)].copy()

            if weather_subset.empty:
                if lieu_key not in ignored_locations:
                    print(
                        f"‚ö†Ô∏è Aucune donn√©e m√©t√©o trouv√©e pour '{lieu_key}' le {date}. Les lignes de cette zone seront ignor√©es.")
                    ignored_locations.add(lieu_key)
                continue

            # Pour chaque ligne de metasail, trouvez la correspondance m√©t√©o la plus proche
            for idx, row_metasail in metasail_subset.iterrows():
                # Calcul de la diff√©rence de temps
                time_diffs = weather_subset['Time_dt'].apply(
                    lambda x: abs(datetime.combine(datetime.min.date(), x) - datetime.combine(datetime.min.date(),
                                                                                              row_metasail[
                                                                                                  'Temps du segment_dt']))
                )

                # Trouver l'index de la correspondance la plus proche
                closest_weather_index = time_diffs.idxmin()

                # R√©cup√©rer la ligne m√©t√©o correspondante
                closest_weather_row = weather_subset.loc[closest_weather_index]

                # Assigner les valeurs m√©t√©o
                self.df_metasail.loc[idx, "Wind Speed (kts)"] = closest_weather_row["Wind Speed (kts)"]
                self.df_metasail.loc[idx, "Wind Direction (deg)"] = closest_weather_row["Wind Direction (deg)"]

        # Nettoyage des colonnes temporaires
        self.df_metasail.drop(columns=['Lat_rounded', 'Lon_rounded', 'Lieu_key'], inplace=True, errors='ignore')

        print("‚úÖ Fusion des donn√©es m√©t√©o termin√©e.")
    def _recalculate_and_clean_metrics(self):
        """
        Recalcule le temps de segment, la VMC moyenne et la vitesse moyenne.
        """
        if self.df_metasail is None:
            return

        print("\n" + "---" * 15)
        print("üìà √âTAPE 3 : CALCUL DES NOUVELLES M√âTRIQUES")
        print("---" * 15)

        required_cols = ["D√©but du segment_dt", "Fin du segment_dt", "Distance r√©elle parcourue segment (m)",
                         "Longueur du segment (m)"]
        if not all(col in self.df_metasail.columns for col in required_cols):
            print("‚ùå Colonnes requises pour le recalcule manquantes.")
            return

        self.df_metasail["delta_time"] = self.df_metasail["Fin du segment_dt"] - self.df_metasail["D√©but du segment_dt"]
        self.df_metasail.loc[self.df_metasail["delta_time"] < timedelta(0), "delta_time"] += timedelta(days=1)
        self.df_metasail["Temps du segment (s)"] = self.df_metasail["delta_time"].dt.total_seconds()

        safe_time = self.df_metasail["Temps du segment (s)"].replace(0, np.nan)
        self.df_metasail["Vitesse moyenne (noeuds)"] = (self.df_metasail[
                                                            "Distance r√©elle parcourue segment (m)"] / safe_time) * 1.94384
        self.df_metasail["VMC moyenne"] = (self.df_metasail["Longueur du segment (m)"] / safe_time) * 1.94384

        cols_to_drop = ["Vitesse maximale (noeuds)", "VMG maximale", "VMC maximale", "VMG moyenne"]
        self.df_metasail.drop(columns=cols_to_drop, inplace=True, errors="ignore")
        print("‚úÖ M√©triques de performance recalcul√©es et nettoy√©es.")

    def save_to_excel(self, chemin_sortie):
        """ Sauvegarde le DataFrame trait√© dans un nouveau fichier Excel. """
        if self.df_metasail is not None:
            self.df_metasail.to_excel(chemin_sortie, index=False)
            print(f"üíæ Fichier trait√© sauvegard√© avec succ√®s sous : {chemin_sortie}")

    def get_dataframe(self):
        """Retourne le DataFrame Metasail trait√©."""
        return self.df_metasail


if __name__ == '__main__':
    fichier_entree_metasail = 'Metasail_Statistics_unified.xlsx'
    fichier_entree_weather = 'weather_data_from_coords.xlsx'
    fichier_sortie = 'Metasail_Statistics_unified_cleaned.xlsx'

    data_processor = DataCleaningAndPreprocessing(fichier_entree_metasail, fichier_entree_weather)

    if data_processor.ready_to_process:
        data_processor.run_cleaning_and_preprocessing()
        data_processor.save_to_excel(fichier_sortie)