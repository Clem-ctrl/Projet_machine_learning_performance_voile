import pandas as pd
import numpy as np
import warnings
from pandas.errors import SettingWithCopyWarning
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
import pickle
import os
import time
from datetime import datetime

# --- 1. Chemin du fichier et gestion des avertissements ---
file_path = r"C:\Projects\Projet_machine_learning_performance_voile\Metasail_Statistics_unified_processed.xlsx"
output_path = r"C:\Projects\Projet_machine_learning_performance_voile\Metasail_random_forest.xlsx"
warnings.filterwarnings('ignore', category=SettingWithCopyWarning)

print("‚úÖ √âtape 1 : Chargement et pr√©paration des donn√©es...\n")

# --- 2. Chargement et v√©rification des donn√©es ---
try:
    df_metasail = pd.read_excel(file_path)
    print("‚úÖ Fichier Excel charg√© avec succ√®s.")
except FileNotFoundError:
    print(f"‚ùå Erreur : Le fichier n'a pas √©t√© trouv√©. Veuillez v√©rifier le chemin d'acc√®s : {file_path}")
    exit()

print("üîç Noms des colonnes dans le fichier Excel :")
print(df_metasail.columns.tolist())

# D√©finition des colonnes
target_col = 'Classement sur le segment'
feature_cols = [
    'Efficacit√© du segment (%)', 'Sexe', "Cat√©gorie d'√¢ge",
    'Wind Speed (kts)', 'Orientation vent metasail',
    'Vitesse moyenne du segment (noeuds)', 'VMC du segment (noeuds)',
    'Allure', 'Wind to speed ratio',
    'Temperature (¬∞C)', 'Pressure (hPa)', 'Humidity (%)', 'Rain (mm)',
    'Classement entr√©e de segment', 'Classement fin de segment'
]

# V√©rification de l'existence des colonnes
colonnes_existantes = [col for col in feature_cols + [target_col] if col in df_metasail.columns]
colonnes_manquantes = [col for col in feature_cols + [target_col] if col not in df_metasail.columns]

if colonnes_manquantes:
    print(
        f"\n‚ùå Erreur : Les colonnes suivantes sont manquantes et le script ne peut pas continuer : {colonnes_manquantes}")
    exit()

data = df_metasail[colonnes_existantes].copy()

# Remplacement des virgules par des points et conversion en num√©rique
cols_to_convert = [
    'Wind Speed (kts)', 'Vitesse moyenne du segment (noeuds)',
    'VMC du segment (noeuds)', 'Wind to speed ratio', 'Temperature (¬∞C)',
    'Pressure (hPa)', 'Humidity (%)', 'Rain (mm)', 'Efficacit√© du segment (%)',
    'Classement entr√©e de segment', 'Classement fin de segment', 'Classement sur le segment'
]
cols_to_convert_existantes = [col for col in cols_to_convert if col in data.columns]

for col in cols_to_convert_existantes:
    data[col] = data[col].astype(str).str.replace(',', '.', regex=False).astype(float)

print("‚úÖ Pr√©paration des donn√©es termin√©e.")

# --- 3. Nettoyage et encodage des donn√©es ---
print("‚öôÔ∏è √âtape 3 : Nettoyage et encodage des donn√©es...\n")

# Conservation des donn√©es U17 et U19
if "Cat√©gorie d'√¢ge" in data.columns:
    data = data[data['Cat√©gorie d\'√¢ge'].isin(['U17', 'U19'])]


# Encodage circulaire pour l'orientation du vent
def circular_encoding(df, col):
    """Effectue un encodage circulaire pour une colonne d'angle."""
    if col in df.columns:
        angle_rad = np.radians(df[col])
        df[f'{col}_sin'] = np.sin(angle_rad)
        df[f'{col}_cos'] = np.cos(angle_rad)
        df.drop([col], axis=1, inplace=True)
    return df


data = circular_encoding(data, 'Orientation vent metasail')

# Encodage des variables cat√©gorielles (One-Hot Encoding)
categorical_cols = ['Sexe', 'Cat√©gorie d\'√¢ge', 'Allure']
categorical_cols_existantes = [col for col in categorical_cols if col in data.columns]
data = pd.get_dummies(data, columns=categorical_cols_existantes, dtype=int)

# Suppression des valeurs manquantes
data.dropna(inplace=True)

print("‚úÖ Donn√©es nettoy√©es et encod√©es avec succ√®s.")
print(f"Nombre total de lignes apr√®s nettoyage : {data.shape[0]}")
print(f"Variables finales : {data.columns.tolist()}\n")

# --- 4. Division des donn√©es et entra√Ænement du mod√®le ---
print("\nüß† √âtape 4 : Division des donn√©es et entra√Ænement du mod√®le...\n")

X = data.drop(columns=[target_col])
y = data[target_col]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)
print("‚úÖ Donn√©es divis√©es avec succ√®s (80% entra√Ænement, 20% test).")
print(f"Taille de l'ensemble d'entra√Ænement : {X_train.shape[0]} lignes")
print(f"Taille de l'ensemble de test : {X_test.shape[0]} lignes\n")

# --- 5. Recherche des meilleurs hyperparam√®tres (Grid Search) ---
print("\n‚öôÔ∏è √âtape 5 : Recherche des meilleurs hyperparam√®tres (Grid Search)...\n")
CHECKPOINT_PATH = "grid_search_checkpoint.pkl"

if os.path.exists(CHECKPOINT_PATH):
    print("‚úÖ Checkpoint trouv√©. Chargement de l'objet GridSearch...")
    with open(CHECKPOINT_PATH, 'rb') as f:
        grid_search = pickle.load(f)
    print("‚úÖ GridSearch charg√© avec succ√®s.")
    total_training_time = 0.0  # Temps non disponible
else:
    print("‚ùå Aucun checkpoint trouv√©. Lancement de GridSearch...")
    start_time = time.time()

    # Nouvelle grille de param√®tres
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 20, 30],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }

    model_to_use = RandomForestRegressor(random_state=13)

    grid_search = GridSearchCV(
        estimator=model_to_use,
        param_grid=param_grid,
        cv=3,
        n_jobs=-1,
        verbose=2
    )

    grid_search.fit(X_train, y_train)

    total_training_time = time.time() - start_time
    with open(CHECKPOINT_PATH, 'wb') as f:
        pickle.dump(grid_search, f)
    print("\n‚úÖ Checkpoint GridSearch sauvegard√©.")
    print(f"‚è≥ Temps d'entra√Ænement total : {total_training_time:.2f} secondes.")

print(f"\n‚úÖ Meilleurs hyperparam√®tres trouv√©s : {grid_search.best_params_}")
print(f"‚úÖ Meilleur score R¬≤ sur l'ensemble d'entra√Ænement : {grid_search.best_score_:.2f}")

best_model = grid_search.best_estimator_

MODEL_PATH = "best_random_forest_model.pkl"
with open(MODEL_PATH, 'wb') as f:
    pickle.dump(best_model, f)
print(f"‚úÖ Le meilleur mod√®le a √©t√© sauvegard√© sous : {MODEL_PATH}")
print("\n‚úÖ Le meilleur mod√®le a √©t√© s√©lectionn√© pour les pr√©dictions finales.")

# --- 6. Pr√©dictions et √©valuation du meilleur mod√®le ---
print("\nüìà √âtape 6 : Pr√©dictions et √©valuation du meilleur mod√®le...\n")
y_pred = best_model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("‚úÖ M√©triques d'√©valuation du meilleur mod√®le :")
print(f"Erreur Absolue Moyenne (MAE) : {mae:.2f}")
print(f"Erreur Quadratique Moyenne (MSE) : {mse:.2f}")
print(f"Coefficient de D√©termination (R¬≤) : {r2:.2f}")

# --- 7. Analyse de l'importance des variables ---
print("\nüîç √âtape 7 : Analyse de l'importance des variables...\n")
feature_importances = pd.Series(best_model.feature_importances_, index=X.columns)
sorted_importances = feature_importances.sort_values(ascending=False)
print("Importance des variables pour la pr√©diction du 'Classement sur le segment':")
print(sorted_importances)

# --- 8. Visualisation de l'importance des variables ---
print("\nüìä √âtape 8 : Cr√©ation du graphique d'importance des variables...\n")
plt.figure(figsize=(12, 8))
sorted_importances.plot(kind='barh', color='skyblue')
plt.title("Importance des variables pour la pr√©diction du classement sur le segment")
plt.xlabel("Importance (score)")
plt.ylabel("Variables")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()
print("\n‚úÖ Graphique d'importance des variables g√©n√©r√© avec succ√®s.")

# --- 9. Sauvegarde des r√©sultats dans un fichier Excel ---
print("\nüìù √âtape 9 : Sauvegarde des r√©sultats dans un fichier Excel...\n")

# Cr√©ation du nom de la feuille de calcul
now = datetime.now()
sheet_name_train = now.strftime("%Y-%m-%d_%H-%M-%S")
sheet_name_test = "Resultats_Test"

# Cr√©ation du DataFrame pour les r√©sultats d'entra√Ænement et d'importance
results_df = pd.DataFrame(columns=['Nom', 'Valeur'])
results_df = pd.concat([results_df, pd.DataFrame([
    {'Nom': 'Meilleurs hyperparam√®tres', 'Valeur': str(grid_search.best_params_)},
    {'Nom': 'Meilleur score R¬≤', 'Valeur': grid_search.best_score_},
    {'Nom': 'Temps d\'entra√Ænement (s)', 'Valeur': total_training_time},
])], ignore_index=True)

# Ajout de l'importance des variables
importance_df = pd.DataFrame(sorted_importances).reset_index()
importance_df.columns = ['Variable', 'Importance']

# Cr√©ation du DataFrame pour les r√©sultats du test
test_results_df = pd.DataFrame(columns=['M√©trique', 'Valeur'])
test_results_df = pd.concat([test_results_df, pd.DataFrame([
    {'M√©trique': 'Erreur Absolue Moyenne (MAE)', 'Valeur': mae},
    {'M√©trique': 'Erreur Quadratique Moyenne (MSE)', 'Valeur': mse},
    {'M√©trique': 'Coefficient de D√©termination (R¬≤)', 'Valeur': r2},
])], ignore_index=True)

# Utilisation de l'API pd.ExcelWriter pour √©crire sur plusieurs feuilles
with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
    # √âcriture des donn√©es d'entra√Ænement et d'importance
    data.to_excel(writer, sheet_name=sheet_name_train, index=False)

    # √âcriture des r√©sultats d'entra√Ænement en dessous des donn√©es
    startrow_results = len(data) + 2
    results_df.to_excel(writer, sheet_name=sheet_name_train, startrow=startrow_results, index=False)

    # √âcriture de l'importance des variables
    startrow_importance = startrow_results + len(results_df) + 2
    importance_df.to_excel(writer, sheet_name=sheet_name_train, startrow=startrow_importance, index=False)

    # √âcriture des r√©sultats de test sur une nouvelle feuille
    test_results_df.to_excel(writer, sheet_name=sheet_name_test, index=False)

print(f"‚úÖ R√©sultats et donn√©es d'entra√Ænement sauvegard√©s dans '{output_path}'.")
print("\nüèÅ Processus termin√© avec succ√®s.")